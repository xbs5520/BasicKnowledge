# OS designs

## OS Type

**Monolithic Kernel**

- Everything (scheduling, memory management, drivers, file systems) runs in **kernel space**.
- Example: Linux, FreeRTOS, ThreadX
-  ‚úÖ Fast (no overhead of message passing). Performance, Simplicity of design, Extensibility via modules.
- ‚ùå Harder to maintain/debug, a buggy driver can crash the whole system.

**Microkernel**

- Keep only the bare minimum in kernel: scheduling, IPC, basic memory.
- Everything else (drivers, file systems) runs in **user space** as services.
- Example: Minix, QNX.
- ‚úÖ More stable, easier to update drivers.
- ‚ùå More overhead (lots of IPC).

**Hybrid Kernel**

- A mix: looks like microkernel, but some parts (drivers, filesystems) still in kernel for performance.
- Example: Windows NT, macOS (XNU).

**Exokernel** (research idea)

- Kernel does almost nothing ‚Äî just **multiplexes hardware**.
- User programs get maximum control.
- ‚úÖ Maximum flexibility.
- ‚ùå Unsafe, complex to program.

## In an embedded system, would you prefer microkernel (safety) or monolithic (speed)?

- If your system is **safety-critical** (e.g., medical device, avionics, automotive), microkernel is often preferred. Why? Because faults in one driver/service won‚Äôt crash the whole system.
- If your system is **resource-limited but needs speed** (e.g., consumer electronics, routers), monolithic is better because it avoids IPC overhead.

## For IoT device which style would you pick?

Devices are usually **tiny (low RAM/CPU)** and need **deterministic response times**.

A **hybrid/minimal microkernel** is often chosen (like Zephyr, QNX, or seL4).

- Core: only scheduling, IPC, memory mgmt.
- Drivers & services: in user space (crashes won‚Äôt kill the kernel).

If I care more about cost & performance (like a smart bulb), I‚Äôd choose a **lightweight monolithic RTOS** (like FreeRTOS).

# Protection & Security

## Protection Mechanisms

**Protection** = *internal mechanisms* to ensure processes don‚Äôt interfere (e.g., memory protection, access control).

- **Memory protection**
  - Use MMU to stop one process from reading another‚Äôs memory.
  - Example: segmentation fault when you dereference invalid pointer.
- **CPU modes**
  - **User mode** vs **Kernel mode**.
  - Kernel mode can do I/O, manage memory. User mode is restricted.
- **Access Control**
  - Permissions (rwx) on files, devices.
  - Access Control Lists (ACLs) for fine-grained control.

## Security Mechanisms

- **Authentication** ‚Äì passwords, biometrics, tokens.
- **Authorization** ‚Äì what you can do after login (permissions).
- **Encryption** ‚Äì protect data at rest and in transit.
- **Auditing** ‚Äì logs to detect misuse.

**Security** = *external defense* against malicious users/attacks (e.g., authentication, encryption).

## Common Security Threats

- **Buffer overflow** ‚Üí inject code.
- **Privilege escalation** ‚Üí normal user gets root access.
- **Race conditions** ‚Üí two processes exploit timing to break protection.
- **Denial of Service (DoS)** ‚Üí hog resources.

## Q&A

### Why do we need **user mode vs kernel mode**?

- **User mode**: runs normal applications with limited privileges.
  - Can‚Äôt directly access hardware (disk, NIC, etc.).
  - If a bug happens, damage is contained.
- **Kernel mode**: runs OS code with full privileges.
  - Can manage memory, devices, and schedule processes.

Separation prevents buggy or malicious apps from crashing the whole system.

### How does the OS stop one process from corrupting another‚Äôs memory?

- Each process has its own **virtual address space**.

- The **MMU (Memory Management Unit)** + page tables map virtual addresses ‚Üí physical addresses.

- Access outside allowed pages = **segmentation fault** (SIGSEGV).

  This isolation ensures one process can‚Äôt read/write another‚Äôs memory.

### What‚Äôs the difference between **authentication** and **authorization**?

- **Authentication** = *Who are you?*
  - Example: password, fingerprint, SSH key.
- **Authorization** = *What are you allowed to do?*
  - Example: after login, you can read `/home/you`, but not `/etc/shadow`.
     üëâ AuthN = identity check, AuthZ = permission check.

### Why are **buffer overflows** dangerous in C/C++?

- C/C++ doesn‚Äôt automatically check array bounds.
- Writing beyond the buffer can overwrite:
  - **Adjacent variables** ‚Üí corrupt data.
  - **Return addresses** ‚Üí attacker injects malicious code.
- Famous example: **stack smashing** ‚Üí attacker hijacks control flow.
   üëâ That‚Äôs why modern OSes use protections: **ASLR, stack canaries, DEP**.

Always connect buffer overflow ‚Üí *security exploit*. It‚Äôs not just a crash, it can give attackers root shell.

# Virtualization&&Containers

## **Virtualization**

- Runs **multiple OSes** on one physical machine.
- Uses a **hypervisor** (e.g., VMware, KVM, Hyper-V).
- Each VM has **its own kernel + OS**.
- Pros: strong isolation, can run different OSes (Linux + Windows on same host).
- Cons: heavy ‚Äî each VM duplicates kernel, memory overhead.

## **Containers**

- Share the **same host kernel**, but isolate **processes, file system, network**.
- Tools: Docker, Podman, containerd.
- Much lighter than VMs.
- You can run 100s of containers where maybe only 10‚Äì20 VMs fit.
- Pros: lightweight, fast startup, great for microservices.
- Cons: weaker isolation (since all share kernel).

## **OS Support**

- Linux provides:
  - **Namespaces** ‚Üí isolation (PID, network, mount, user).
  - **cgroups** ‚Üí resource control (CPU, memory limits).

## **Comparison**

| Feature        | Virtual Machine                      | Container                        |
| -------------- | ------------------------------------ | -------------------------------- |
| Isolation      | Strong (separate OS)                 | Weaker (shared kernel)           |
| Startup Time   | Slow (seconds‚Äìminutes)               | Fast (ms‚Äìs)                      |
| Resource Usage | Heavy (full OS per VM)               | Light (process-level)            |
| Portability    | OS-level images                      | Application-level images         |
| Use Cases      | Run Windows on Linux, full isolation | Microservices, cloud apps, CI/CD |

## Q&A

### Why are **containers faster than VMs**?

- **Shared kernel**: Containers don‚Äôt need to boot a full OS‚Äîjust processes.
- **No hardware emulation**: VMs need a hypervisor to emulate hardware for each guest OS.
- **Lightweight filesystem**: Containers use layered images, so less disk/memory overhead.
- **Startup time**: Containers can start in milliseconds; VMs often take seconds or minutes.

### How do **containers achieve isolation**?

Containers use **Linux kernel features**:

- **Namespaces** ‚Üí isolate process IDs, network stack, mount points, users.
- **cgroups (control groups)** ‚Üí limit CPU, memory, I/O, preventing one container from starving others.
- **Capabilities** ‚Üí restrict what processes inside a container can do, e.g., prevent them from changing kernel settings.

This gives the **illusion of separate OSes** without actually duplicating a kernel.

### When would you pick a **VM instead of a container**?

- **Strong isolation needed**: You don‚Äôt trust the code inside, or need different OSes.
- **Different OS environments**: Run Windows on Linux, or legacy OSes.
- **Full kernel testing**: If you need a completely separate kernel for testing.
- **Security-critical workloads**: Banking, medical, or government systems may prefer VMs.